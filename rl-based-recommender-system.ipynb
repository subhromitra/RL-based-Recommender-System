{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T09:21:30.711787Z","iopub.execute_input":"2025-08-17T09:21:30.712030Z","iopub.status.idle":"2025-08-17T09:21:33.124542Z","shell.execute_reply.started":"2025-08-17T09:21:30.712001Z","shell.execute_reply":"2025-08-17T09:21:33.123344Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!wget --no-check-certificate https://data.recsys.synerise.com/dataset/ubc_data/ubc_data.tar.gz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T07:53:00.985827Z","iopub.execute_input":"2025-08-15T07:53:00.986034Z","iopub.status.idle":"2025-08-15T07:53:43.394322Z","shell.execute_reply.started":"2025-08-15T07:53:00.986017Z","shell.execute_reply":"2025-08-15T07:53:43.393346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tarfile\n\n# Path to your tar.gz file\ntar_path = \"/kaggle/working/ubc_data.tar.gz\"\n\n# Extract files\nwith tarfile.open(tar_path, \"r:gz\") as tar:\n    tar.extractall(\"ubc_data_extracted\")  # creates folder with extracted files\n    print(\"Files extracted to 'ubc_data_extracted'\")\n    print(\"Contents:\", tar.getnames())  # list of files inside\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T07:59:47.477886Z","iopub.execute_input":"2025-08-15T07:59:47.478210Z","iopub.status.idle":"2025-08-15T08:00:04.416060Z","shell.execute_reply.started":"2025-08-15T07:59:47.478182Z","shell.execute_reply":"2025-08-15T08:00:04.415317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nRecSys RL Recommender (Double-DQN) with Propensity Integration\n---------------------------------------------------------------\nThis single-file pipeline:\n- Loads Parquet event files and target propensity `.npy` arrays from an extracted folder (e.g., 'ubc_data_extracted')\n- Performs exploration and cleaning\n- Builds sessionized episodes\n- Constructs stable feature vectors for (state, candidate)\n- Integrates product propensity (popularity propensity) as a feature and supports re-ranking by propensity\n- Implements a dense-reward environment\n- Trains a Double + Dueling DQN policy (policy + target nets)\n- Evaluates offline with HR@K, NDCG@K, and reward/session\n\nNotes:\n- Edit DATA_DIR to point to the folder where you extracted ubc_data.tar.gz (folder that contains the parquet files and target/ folder).\n- This file assumes parquet and numpy files are present as described previously.\n- Use USE_SYNTHETIC=True for a small in-memory test instead of reading files.\n\nAuthor: ChatGPT (GPT-5 Thinking mini)\n\"\"\"\n\nfrom __future__ import annotations\nimport os\nimport math\nimport json\nimport time\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Tuple, Optional, Any\n\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict, Counter, deque\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# -----------------------------\n# Config\n# -----------------------------\nUSE_SYNTHETIC = False\nDATA_DIR = \"/kaggle/working/ubc_data_extracted\"  # <- set this to your extracted folder path\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\n\n# Embedding dims\nEMB_DIM_ITEM = 128\nEMB_DIM_QUERY = 128\nEMB_DIM_URL = 64\n\n# Sessionization\nSESSION_GAP_MIN = 30\nMAX_STEPS_PER_SESSION = 20\n\n# Candidate gen\nCANDIDATE_POOL_SIZE = 200\n\n# Reward weights (dense reward)\nW_BUY = 5.0\nW_A2C = 2.0\nW_RMC = 1.0\nW_CAT = 0.5\nW_PV = 0.2\nW_QRY = 0.2\nW_DIV = 0.1\nW_REP = 0.2\nTIME_DECAY_TAU_SEC = 60.0\nGAMMA = 0.9\n\n# Training\nBATCH_SIZE = 128\nREPLAY_CAP = 200_000\nLR = 1e-3\nEPSILON_START = 0.2\nEPSILON_END = 0.05\nEPSILON_DECAY_STEPS = 50_000\nTARGET_UPDATE_FREQ = 2_000\nTRAIN_STEPS = 50_000\nEVAL_EVERY = 5_000\nTOPK = 10\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# -----------------------------\n# Utilities\n# -----------------------------\n\ndef parse_ts(s: Any) -> pd.Timestamp:\n    return pd.to_datetime(s, utc=True, errors='coerce')\n\nclass HashVectorizer:\n    def __init__(self, dim: int, seed: int = 42):\n        self.dim = dim\n        self.seed = seed\n    def _bytes(self, x: Any) -> bytes:\n        if isinstance(x, bytes): return x\n        if isinstance(x, (list, tuple)): return json.dumps(x, sort_keys=True).encode('utf-8')\n        return str(x).encode('utf-8')\n    def transform_one(self, x: Any) -> np.ndarray:\n        b = self._bytes(x)\n        rs = np.random.RandomState(abs(hash((b, self.seed))) % (2**32))\n        v = rs.normal(0, 1.0, size=self.dim)\n        v /= (np.linalg.norm(v) + 1e-8)\n        return v.astype(np.float32)\n\nitem_vec = HashVectorizer(EMB_DIM_ITEM)\nquery_vec = HashVectorizer(EMB_DIM_QUERY)\nurl_vec = HashVectorizer(EMB_DIM_URL)\n\ndef decode_embedding(obj: Any, kind: str = \"item\") -> np.ndarray:\n    if kind == \"item\": return item_vec.transform_one(obj)\n    if kind == \"query\": return query_vec.transform_one(obj)\n    if kind == \"url\": return url_vec.transform_one(obj)\n    raise ValueError(\"unknown kind\")\n\n# -----------------------------\n# Data loading\n# -----------------------------\n\ndef load_parquets_and_targets(data_dir: str) -> Dict[str, Any]:\n    \"\"\"Load parquet event files and target propensity numpy arrays.\n    Expects files described earlier.\n    \"\"\"\n    if USE_SYNTHETIC:\n        return make_synth_data_for_pipeline()\n\n    def rp(fname):\n        p = os.path.join(data_dir, fname)\n        if not os.path.exists(p):\n            raise FileNotFoundError(p)\n        return pd.read_parquet(p)\n\n    data = {}\n    data['product_properties'] = rp('product_properties.parquet')\n    data['product_buy'] = rp('product_buy.parquet')\n    data['add_to_cart'] = rp('add_to_cart.parquet')\n    data['remove_from_cart'] = rp('remove_from_cart.parquet')\n    data['page_visit'] = rp('page_visit.parquet')\n    data['search_query'] = rp('search_query.parquet')\n\n    # load numpy targets if present\n    targ_dir = os.path.join(data_dir, 'target')\n    if os.path.isdir(targ_dir):\n        def ln(p):\n            f = os.path.join(p)\n            if os.path.exists(f):\n                return np.load(f, allow_pickle=True)\n            return None\n        data['propensity_sku'] = None\n        data['propensity_category'] = None\n        sku_p = os.path.join(targ_dir, 'popularity_propensity_sku.npy')\n        cat_p = os.path.join(targ_dir, 'popularity_propensity_category.npy')\n        if os.path.exists(sku_p):\n            data['propensity_sku'] = np.load(sku_p, allow_pickle=True) if os.path.getsize(sku_p)>0 else None\n        if os.path.exists(cat_p):\n            data['propensity_category'] = np.load(cat_p, allow_pickle=True) if os.path.getsize(cat_p)>0 else None\n    else:\n        data['propensity_sku'] = None\n        data['propensity_category'] = None\n\n    return data\n\n# -----------------------------\n# (Optional) Synthetic data helper\n# -----------------------------\n\ndef make_synth_data_for_pipeline():\n    # For brevity return minimal synthetic datasets similar to earlier function\n    n_users=200; n_items=1000\n    rng = np.random.RandomState(RANDOM_SEED)\n    prod = pd.DataFrame({'sku': np.arange(n_items), 'category': rng.randint(0,20,n_items), 'price': rng.randint(0,10,n_items), 'embedding': [f'pq_{i}' for i in range(n_items)]})\n    rows_buy=[]; rows_a2c=[]; rows_rmc=[]; rows_pv=[]; rows_qry=[]\n    base = pd.Timestamp('2025-01-01', tz='UTC')\n    for u in range(n_users):\n        t = base\n        for s in range(rng.randint(3,10)):\n            t += pd.Timedelta(minutes=rng.randint(1,60))\n            if rng.rand()<0.5:\n                sku = rng.randint(0,n_items)\n                rows_a2c.append({'client_id':u,'timestamp':t,'sku':sku})\n                if rng.rand()<0.5:\n                    rows_buy.append({'client_id':u,'timestamp':t+pd.Timedelta(minutes=1),'sku':sku})\n            if rng.rand()<0.3:\n                rows_pv.append({'client_id':u,'timestamp':t,'url':rng.randint(0,200)})\n            if rng.rand()<0.2:\n                rows_qry.append({'client_id':u,'timestamp':t,'query':f'q_{rng.randint(0,50)}'})\n    return {\n        'product_properties': prod,\n        'product_buy': pd.DataFrame(rows_buy),\n        'add_to_cart': pd.DataFrame(rows_a2c),\n        'remove_from_cart': pd.DataFrame(rows_rmc),\n        'page_visit': pd.DataFrame(rows_pv),\n        'search_query': pd.DataFrame(rows_qry),\n        'propensity_sku': {i: float(0.01 + (i%50)/100.0) for i in range(prod.shape[0])},\n        'propensity_category': {c: 0.05 + (c%10)/100.0 for c in range(20)}\n    }\n\n# -----------------------------\n# Cleaning & sessionization\n# -----------------------------\n\ndef clean_and_sessionize(data: Dict[str, Any]) -> pd.DataFrame:\n    prod = data['product_properties'].copy()\n    prod['sku'] = prod['sku'].astype('int64')\n    prod['category'] = prod['category'].astype('int64')\n    prod['price'] = prod['price'].astype('int64')\n    data['product_properties'] = prod\n\n    for k in ['product_buy','add_to_cart','remove_from_cart']:\n        df = data[k].copy()\n        df['client_id'] = df['client_id'].astype('int64')\n        df['sku'] = df['sku'].astype('int64')\n        df['timestamp'] = df['timestamp'].apply(parse_ts)\n        data[k] = df.sort_values(['client_id','timestamp']).reset_index(drop=True)\n\n    pv = data['page_visit'].copy()\n    pv['client_id'] = pv['client_id'].astype('int64')\n    pv['url'] = pv['url'].astype('int64')\n    pv['timestamp'] = pv['timestamp'].apply(parse_ts)\n    data['page_visit'] = pv.sort_values(['client_id','timestamp']).reset_index(drop=True)\n\n    sq = data['search_query'].copy()\n    sq['client_id'] = sq['client_id'].astype('int64')\n    sq['timestamp'] = sq['timestamp'].apply(parse_ts)\n    data['search_query'] = sq.sort_values(['client_id','timestamp']).reset_index(drop=True)\n\n    # unify\n    def add(df, etype):\n        if df is None or df.shape[0]==0:\n            return pd.DataFrame()\n        df2 = df.copy()\n        df2['event_type'] = etype\n        return df2\n    dfs = [add(data.get('product_buy'), 'buy'), add(data.get('add_to_cart'),'a2c'), add(data.get('remove_from_cart'),'rmc'), add(data.get('page_visit'),'pv'), add(data.get('search_query'),'qry')]\n    allv = pd.concat(dfs, ignore_index=True, sort=False).sort_values(['client_id','timestamp']).reset_index(drop=True)\n\n    gap = pd.Timedelta(minutes=SESSION_GAP_MIN)\n    allv['prev_ts'] = allv.groupby('client_id')['timestamp'].shift(1)\n    new_sess = (allv['prev_ts'].isna()) | ((allv['timestamp'] - allv['prev_ts']) > gap)\n    allv['session_id'] = new_sess.groupby(allv['client_id']).cumsum()\n    allv['step'] = allv.groupby(['client_id','session_id']).cumcount()\n    allv = allv.drop(columns=['prev_ts'])\n    return allv\n\n# -----------------------------\n# URL->category co-occurrence\n# -----------------------------\n\ndef build_url_category_model(pv: pd.DataFrame, item_events: pd.DataFrame, prod: pd.DataFrame, window_min: int = 10) -> Dict[int, Dict[int, float]]:\n    if pv.empty or item_events.empty:\n        return {}\n    window = pd.Timedelta(minutes=window_min)\n    prod_cat = prod.set_index('sku')['category'].to_dict()\n    counts = defaultdict(Counter)\n    item_by_client = item_events.groupby('client_id')\n    for client, gpv in pv.groupby('client_id'):\n        if client not in item_by_client.groups: continue\n        gi = item_by_client.get_group(client).reset_index(drop=True)\n        i_idx = 0\n        for _, row in gpv.iterrows():\n            t = row['timestamp']\n            while i_idx < len(gi) and gi.loc[i_idx, 'timestamp'] < t:\n                i_idx += 1\n            j = i_idx\n            while j < len(gi) and gi.loc[j, 'timestamp'] <= t + window:\n                sku = int(gi.loc[j, 'sku']) if 'sku' in gi.columns and not pd.isna(gi.loc[j,'sku']) else None\n                if sku is not None and sku in prod_cat:\n                    counts[int(row['url'])][int(prod_cat[sku])] += 1\n                j += 1\n    model = {}\n    for url, c in counts.items():\n        total = sum(c.values())\n        if total==0: continue\n        model[url] = {cat: cnt/total for cat,cnt in c.items()}\n    return model\n\n# -----------------------------\n# Master items table\n# -----------------------------\n\ndef build_item_table(prod: pd.DataFrame, propensity_sku: Optional[Dict[int,float]]=None, propensity_cat: Optional[Dict[int,float]]=None):\n    items = prod[['sku','category','price','name']].copy()\n    items['emb_vec'] = items['name'].apply(lambda x: decode_embedding(x,'item'))\n    mat = np.vstack(items['emb_vec'].values)\n    norms = np.linalg.norm(mat, axis=1, keepdims=True)+1e-8\n    mat = mat / norms\n    items['emb_vec'] = list(mat)\n\n    if propensity_sku is not None:\n        items['propensity_sku'] = items['sku'].map(lambda s: float(propensity_sku.get(int(s), 1e-3)))\n    else:\n        items['propensity_sku'] = 0.01\n    if propensity_cat is not None:\n        items['propensity_category'] = items['category'].map(lambda c: float(propensity_cat.get(int(c), 0.01)))\n    else:\n        items['propensity_category'] = 0.01\n    return items\n\n# -----------------------------\n# User long-term embeddings\n# -----------------------------\n\ndef build_user_long_term(allv: pd.DataFrame, items: pd.DataFrame) -> Dict[int, np.ndarray]:\n    sku2vec = items.set_index('sku')['emb_vec'].to_dict()\n    out = {}\n    for uid, g in allv[allv['event_type'].isin(['buy','a2c'])].groupby('client_id'):\n        vecs = [sku2vec[int(s)] for s in g['sku'].values if int(s) in sku2vec]\n        if len(vecs)==0:\n            out[int(uid)] = np.zeros(EMB_DIM_ITEM, dtype=np.float32)\n        else:\n            v = np.vstack(vecs).mean(axis=0)\n            v /= (np.linalg.norm(v)+1e-8)\n            out[int(uid)] = v.astype(np.float32)\n    return out\n\n# -----------------------------\n# Candidate generator\n# -----------------------------\nclass CandidateGenerator:\n    def __init__(self, items: pd.DataFrame, popular_skus: np.ndarray):\n        self.items = items\n        self.popular = popular_skus\n        self.item_mat = np.vstack(items['emb_vec'].values)\n    def ann(self, q: np.ndarray, k: int) -> List[int]:\n        qn = q / (np.linalg.norm(q)+1e-8)\n        sims = (self.item_mat @ qn)\n        idx = np.argpartition(-sims, kth=min(k, len(sims)-1))[:k]\n        idx = idx[np.argsort(-sims[idx])]\n        return [int(self.items.iloc[i]['sku']) for i in idx]\n    def get_candidates(self, user_vec: np.ndarray, last_cat: Optional[int], exclude: set[int], k: int = CANDIDATE_POOL_SIZE) -> List[int]:\n        cands = []\n        if np.linalg.norm(user_vec) > 0:\n            cands += self.ann(user_vec, k//2)\n        for s in self.popular:\n            if len(cands) >= k: break\n            cands.append(int(s))\n        out=[]; seen=set()\n        for s in cands:\n            if s in exclude or s in seen: continue\n            seen.add(s); out.append(s)\n            if len(out) >= k: break\n        return out\n\n# -----------------------------\n# Feature builder (includes propensity)\n# -----------------------------\nFEATURE_DIM = 2*EMB_DIM_ITEM + 6  # user_lt + sess_vec + [sim_user, sim_sess, sim_q, div, propensity_sku, propensity_cat]\n@dataclass\nclass SessionState:\n    user_id: int\n    session_id: int\n    step: int\n    user_lt: np.ndarray\n    sess_vec: np.ndarray\n    last_skus: deque\n    last_cats: deque\n    cart: Counter\n    last_query: Optional[np.ndarray]\n    last_url: Optional[int]\n    last_recs: List[int]\n    last_time: pd.Timestamp\n\nclass FeatureBuilder:\n    def __init__(self, items: pd.DataFrame):\n        self.sku2vec = items.set_index('sku')['emb_vec'].to_dict()\n        self.sku2cat = items.set_index('sku')['category'].to_dict()\n        self.sku2price = items.set_index('sku')['price'].to_dict()\n        self.sku2prop = items.set_index('sku')['propensity_sku'].to_dict()\n        self.cat2prop = items.set_index('sku')['propensity_category'].to_dict()\n    def build(self, state: SessionState, candidates: List[int]) -> Tuple[np.ndarray, List[Dict[str,Any]]]:\n        feats=[]; meta=[]\n        for sku in candidates:\n            ivec = self.sku2vec[sku]\n            cat = self.sku2cat[sku]\n            sim_user = cosine(state.user_lt, ivec)\n            sim_sess = cosine(state.sess_vec, ivec)\n            sim_q = cosine(state.last_query, ivec) if state.last_query is not None else 0.0\n            div = 0.0\n            if state.last_recs:\n                div = float(min([1.0 - cosine(self.sku2vec[r], ivec) for r in state.last_recs]))\n            p_sku = float(self.sku2prop.get(sku, 0.01))\n            p_cat = float(self.cat2prop.get(sku, 0.01))\n            f = np.concatenate([state.user_lt, state.sess_vec, np.array([sim_user, sim_sess, sim_q, div, p_sku, p_cat], dtype=np.float32)])\n            feats.append(f)\n            meta.append({'sku':sku,'cat':cat,'p_sku':p_sku,'p_cat':p_cat})\n        X = np.vstack(feats).astype(np.float32)\n        return X, meta\n\ndef cosine(a: np.ndarray, b: np.ndarray) -> float:\n    if a is None or b is None: return 0.0\n    na = np.linalg.norm(a); nb = np.linalg.norm(b)\n    if na < 1e-8 or nb < 1e-8: return 0.0\n    return float(np.dot(a,b)/(na*nb))\n\n# -----------------------------\n# Environment with dense rewards\n# -----------------------------\nclass RLEnv:\n    def __init__(self, allv: pd.DataFrame, items: pd.DataFrame, url_cat_model: Dict[int, Dict[int,float]], user_lt: Dict[int,np.ndarray]):\n        self.allv = allv\n        self.items = items\n        self.url_cat_model = url_cat_model\n        self.user_lt = user_lt\n        self.sku2vec = items.set_index('sku')['emb_vec'].to_dict()\n        self.sku2cat = items.set_index('sku')['category'].to_dict()\n        self.sku2prop = items.set_index('sku')['propensity_sku'].to_dict()\n        popular = allv[allv['event_type'].isin(['buy','a2c'])]['sku'].value_counts().index.values\n        self.cgen = CandidateGenerator(items, popular)\n        self.fbuilder = FeatureBuilder(items)\n        self.sessions = list(allv.groupby(['client_id','session_id']).groups.keys())\n        self.sessions_idx = 0\n    def _init_state(self, client_id:int, session_id:int) -> SessionState:\n        g = self.allv[(self.allv.client_id==client_id)&(self.allv.session_id==session_id)].reset_index(drop=True)\n        t0 = g.loc[0,'timestamp']\n        uvec = self.user_lt.get(int(client_id), np.zeros(EMB_DIM_ITEM, dtype=np.float32))\n        st = SessionState(user_id=int(client_id), session_id=int(session_id), step=0, user_lt=uvec, sess_vec=np.zeros(EMB_DIM_ITEM,dtype=np.float32), last_skus=deque(maxlen=5), last_cats=deque(maxlen=5), cart=Counter(), last_query=None, last_url=None, last_recs=[], last_time=t0)\n        st._events = g; st._cursor=0; st._done=False\n        return st\n    def _advance_once(self, state: SessionState):\n        g = state._events\n        if state._cursor >= len(g): state._done=True; return\n        row = g.loc[state._cursor]; state._cursor += 1\n        state.last_time = row['timestamp']\n        et = row['event_type']\n        if et in ('buy','a2c','rmc') and 'sku' in row and not pd.isna(row['sku']):\n            sku = int(row['sku']);\n            if sku in self.sku2vec:\n                state.sess_vec = (state.sess_vec*0.7 + self.sku2vec[sku]*0.3).astype(np.float32)\n                state.last_skus.append(sku); state.last_cats.append(int(self.sku2cat.get(sku, -1)))\n            if et=='a2c': state.cart[sku]+=1\n            if et=='rmc': state.cart[sku]-=1; state.cart.pop(sku,None)\n        elif et=='qry':\n            state.last_query = decode_embedding(row['query'],'query')\n            state.sess_vec = (state.sess_vec*0.6 + state.last_query[:EMB_DIM_ITEM]*0.4).astype(np.float32)\n        elif et=='pv':\n            state.last_url = int(row['url'])\n        state.step += 1\n    def reset(self) -> SessionState:\n        if not self.sessions: raise RuntimeError('no sessions')\n        if self.sessions_idx >= len(self.sessions): self.sessions_idx = 0\n        cid, sid = self.sessions[self.sessions_idx]; self.sessions_idx += 1\n        st = self._init_state(cid, sid); self._advance_once(st); return st\n    def candidate_features(self, state: SessionState):\n        exclude = set(state.last_recs)\n        last_cat = state.last_cats[-1] if state.last_cats else None\n        cands = self.cgen.get_candidates(state.user_lt, last_cat, exclude, CANDIDATE_POOL_SIZE)\n        X, meta = self.fbuilder.build(state, cands)\n        return cands, X, meta\n    def step(self, state: SessionState, action_sku: int) -> Tuple[SessionState, float, bool, Dict[str,Any]]:\n        prev_time = state.last_time; prev_recs = list(state.last_recs); state.last_recs = (prev_recs + [action_sku])[-5:]\n        g = state._events; reward=0.0\n        if state._cursor < len(g):\n            row = g.loc[state._cursor]; dt = (row['timestamp'] - prev_time).total_seconds(); credit = math.exp(-max(0.0,dt)/TIME_DECAY_TAU_SEC)\n            if row['event_type'] in ('buy','a2c','rmc') and 'sku' in row and not pd.isna(row['sku']):\n                sku = int(row['sku'])\n                if row['event_type']=='buy' and sku==action_sku: reward += W_BUY*credit\n                if row['event_type']=='a2c' and sku==action_sku: reward += W_A2C*credit\n                if row['event_type']=='rmc' and sku==action_sku: reward -= W_RMC*credit\n                act_cat = self.sku2cat.get(action_sku,None); ev_cat = self.sku2cat.get(sku,None)\n                if act_cat is not None and ev_cat is not None and act_cat==ev_cat and row['event_type'] in ('buy','a2c'):\n                    reward += W_CAT*credit\n            elif row['event_type']=='pv':\n                url = int(row['url']) if not pd.isna(row['url']) else None\n                act_cat = self.sku2cat.get(action_sku,None)\n                if url is not None and act_cat is not None and url in self.url_cat_model:\n                    p = self.url_cat_model[url].get(act_cat,0.0); reward += W_PV * p * credit\n            elif row['event_type']=='qry':\n                qv = decode_embedding(row['query'],'query'); iv = self.sku2vec[action_sku]\n                sim = max(0.0, cosine(qv, iv)); reward += W_QRY * sim * credit\n        if prev_recs:\n            iv = self.sku2vec[action_sku]; mind = min([1.0 - cosine(self.sku2vec[r], iv) for r in prev_recs])\n            reward += W_DIV * mind\n        if action_sku in prev_recs: reward -= W_REP\n        self._advance_once(state)\n        done = state._done or (state.step >= MAX_STEPS_PER_SESSION)\n        return state, float(reward), done, {}\n\n# -----------------------------\n# Replay buffer\n# -----------------------------\nclass ReplayBuffer:\n    def __init__(self, cap=REPLAY_CAP): self.buf = deque(maxlen=cap)\n    def push(self, s, a, r, ns, done): self.buf.append((s,a,r,ns,done))\n    def sample(self, bs):\n        idx = np.random.choice(len(self.buf), size=bs, replace=False)\n        batch = [self.buf[i] for i in idx]\n        s,a,r,ns,d = zip(*batch)\n        return np.stack(s), np.array(a), np.array(r,dtype=np.float32), np.stack(ns), np.array(d,dtype=np.float32)\n    def __len__(self): return len(self.buf)\n\n# -----------------------------\n# Model: Dueling MLP (per-candidate -> scalar Q)\n# -----------------------------\nclass DuelingMLP(nn.Module):\n    def __init__(self, in_dim:int, hidden:int=256):\n        super().__init__();\n        self.shared = nn.Sequential(nn.Linear(in_dim, hidden), nn.ReLU(), nn.Linear(hidden, hidden), nn.ReLU())\n        self.V = nn.Linear(hidden,1); self.A = nn.Linear(hidden,1)\n    def forward(self,x): h=self.shared(x); V=self.V(h); A=self.A(h); return V + (A - A.mean(dim=0,keepdim=True))\n\n# -----------------------------\n# Training and evaluation\n# -----------------------------\n\ndef epsilon_by_step(step:int)->float:\n    if step>=EPSILON_DECAY_STEPS: return EPSILON_END\n    frac = step/EPSILON_DECAY_STEPS; return EPSILON_START + (EPSILON_END-EPSILON_START)*frac\n\ndef offline_eval(env:RLEnv, model:nn.Module, n_sessions:int=200, topk:int=TOPK)->Dict[str,float]:\n    model.eval(); hits=0; ndcg=0.0; total=0; rew=0.0\n    for _ in range(n_sessions):\n        st = env.reset(); done=False\n        while not done:\n            cands,X,meta = env.candidate_features(st)\n            with torch.no_grad(): q = model(torch.from_numpy(X).to(DEVICE)).squeeze(-1).cpu().numpy()\n            order = np.argsort(-q); top = [cands[i] for i in order[:topk]]\n            best = top[0] if len(top)>0 else cands[0]\n            st, r, done, _ = env.step(st, best); rew += r\n            g = st._events; cur = st._cursor-1\n            if 0<=cur<len(g):\n                row = g.loc[cur]\n                if row['event_type'] in ('buy','a2c') and not pd.isna(row.get('sku', np.nan)):\n                    sku = int(row['sku'])\n                    total += 1\n                    if sku in top:\n                        hits += 1; rank = top.index(sku)+1; ndcg += 1.0/math.log2(rank+1)\n    return {'HR@K': hits/max(1,total), 'NDCG@K': ndcg/max(1,total), 'Reward/session': rew/max(1,n_sessions)}\n\ndef train_loop(env:RLEnv):\n    policy = DuelingMLP(FEATURE_DIM).to(DEVICE); target = DuelingMLP(FEATURE_DIM).to(DEVICE); target.load_state_dict(policy.state_dict())\n    opt = torch.optim.Adam(policy.parameters(), lr=LR); buf = ReplayBuffer()\n    step=0; st = env.reset()\n    while step < TRAIN_STEPS:\n        cands,X,meta = env.candidate_features(st)\n        X_t = torch.from_numpy(X).to(DEVICE)\n        eps = epsilon_by_step(step)\n        with torch.no_grad(): qvals = policy(X_t).squeeze(-1).cpu().numpy()\n        if np.random.rand() < eps: a_idx = np.random.randint(len(cands))\n        else: a_idx = int(np.argmax(qvals))\n        action_sku = cands[a_idx]\n        st_next, reward, done, _ = env.step(st, action_sku)\n        ncands,nX,nmeta = env.candidate_features(st_next)\n        # store chosen feature row and next-state candidate matrix (fixed-size)\n        s_row = X[a_idx]\n        # pad/truncate nX to fixed CANDIDATE_POOL_SIZE\n        def fix_stack(mat, target_c=CANDIDATE_POOL_SIZE):\n            c = mat.shape[0]\n            if c >= target_c: return mat[:target_c]\n            pad = np.zeros((target_c-c, mat.shape[1]), dtype=np.float32)\n            return np.vstack([mat, pad])\n        ns_fixed = fix_stack(nX)\n        buf.push(s_row, 0, reward, ns_fixed, float(done))\n        if len(buf) >= BATCH_SIZE:\n            s_b,a_b,r_b,ns_b,d_b = buf.sample(BATCH_SIZE)\n            s_b = torch.from_numpy(s_b).to(DEVICE); r_b = torch.from_numpy(r_b).to(DEVICE); d_b = torch.from_numpy(d_b).to(DEVICE)\n            ns_b_t = torch.from_numpy(ns_b.reshape(BATCH_SIZE, CANDIDATE_POOL_SIZE, FEATURE_DIM)).to(DEVICE)\n            with torch.no_grad():\n                q_next_policy = policy(ns_b_t.view(-1,FEATURE_DIM)).view(BATCH_SIZE, CANDIDATE_POOL_SIZE)\n                a_star = torch.argmax(q_next_policy, dim=1, keepdim=True)\n                q_next_target = target(ns_b_t.view(-1,FEATURE_DIM)).view(BATCH_SIZE, CANDIDATE_POOL_SIZE)\n                q_next = torch.gather(q_next_target, 1, a_star).squeeze(1)\n                y = r_b + (1.0 - d_b) * GAMMA * q_next\n            q_curr = policy(s_b).squeeze(-1)\n            loss = F.mse_loss(q_curr, y)\n            opt.zero_grad(); loss.backward(); opt.step(); nn.utils.clip_grad_norm_(policy.parameters(), 5.0)\n            if step % TARGET_UPDATE_FREQ == 0:\n                target.load_state_dict(policy.state_dict())\n        st = st_next\n        if done: st = env.reset()\n        if (step % EVAL_EVERY == 0) and step>0:\n            metrics = offline_eval(env, policy, n_sessions=50, topk=TOPK)\n            print(f\"[step {step}] eps={eps:.3f} metrics={metrics}\")\n        step += 1\n    return policy\n\n# -----------------------------\n# Main orchestration\n# -----------------------------\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T19:10:26.747914Z","iopub.execute_input":"2025-08-16T19:10:26.748303Z","iopub.status.idle":"2025-08-16T19:10:31.024689Z","shell.execute_reply.started":"2025-08-16T19:10:26.748278Z","shell.execute_reply":"2025-08-16T19:10:31.023932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['product_properties']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T17:11:47.781264Z","iopub.execute_input":"2025-08-16T17:11:47.781586Z","iopub.status.idle":"2025-08-16T17:11:47.792131Z","shell.execute_reply.started":"2025-08-16T17:11:47.781552Z","shell.execute_reply":"2025-08-16T17:11:47.791373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data[\"product_properties\"].columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T04:02:29.202658Z","iopub.execute_input":"2025-08-18T04:02:29.203612Z","iopub.status.idle":"2025-08-18T04:02:29.212112Z","shell.execute_reply.started":"2025-08-18T04:02:29.203578Z","shell.execute_reply":"2025-08-18T04:02:29.210958Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['sku', 'category', 'price', 'name'], dtype='object')"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"#### SKU stands Stock Keeping Unit, is a unique alphanumeric code assigned to a product for inventory management purposes. It helps businesses track inventory, analyze sales, and manage stock levels effectively.","metadata":{}},{"cell_type":"code","source":"data[\"product_buy\"].columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T04:02:35.325353Z","iopub.execute_input":"2025-08-18T04:02:35.325661Z","iopub.status.idle":"2025-08-18T04:02:35.332629Z","shell.execute_reply.started":"2025-08-18T04:02:35.325638Z","shell.execute_reply":"2025-08-18T04:02:35.331591Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Index(['client_id', 'timestamp', 'sku'], dtype='object')"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data[\"add_to_cart\"].columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T04:02:38.222324Z","iopub.execute_input":"2025-08-18T04:02:38.222724Z","iopub.status.idle":"2025-08-18T04:02:38.230566Z","shell.execute_reply.started":"2025-08-18T04:02:38.222696Z","shell.execute_reply":"2025-08-18T04:02:38.229329Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Index(['client_id', 'timestamp', 'sku'], dtype='object')"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"data[\"remove_from_cart\"].columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T04:02:40.603767Z","iopub.execute_input":"2025-08-18T04:02:40.604287Z","iopub.status.idle":"2025-08-18T04:02:40.614706Z","shell.execute_reply.started":"2025-08-18T04:02:40.604247Z","shell.execute_reply":"2025-08-18T04:02:40.613187Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['client_id', 'timestamp', 'sku'], dtype='object')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"data[\"page_visit\"].columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T04:02:42.978670Z","iopub.execute_input":"2025-08-18T04:02:42.980084Z","iopub.status.idle":"2025-08-18T04:02:42.988435Z","shell.execute_reply.started":"2025-08-18T04:02:42.980047Z","shell.execute_reply":"2025-08-18T04:02:42.987236Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Index(['client_id', 'timestamp', 'url'], dtype='object')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"data[\"search_query\"].columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T04:02:46.138515Z","iopub.execute_input":"2025-08-18T04:02:46.138855Z","iopub.status.idle":"2025-08-18T04:02:46.145759Z","shell.execute_reply.started":"2025-08-18T04:02:46.138832Z","shell.execute_reply":"2025-08-18T04:02:46.144777Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Index(['client_id', 'timestamp', 'query'], dtype='object')"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"What this function does (step-by-step)\n\nStandardizes data types\n\nEnsures sku, category, price, and client_id are integers.\n\nConverts timestamp strings into proper datetime objects using parse_ts.\n\nSorts each event table\n\nOrders rows by client_id then by timestamp.\n\nThis helps when grouping events into sessions.\n\nCombines all events into one big table\n\nCreates a column event_type with values like \"buy\", \"a2c\", \"rmc\", \"pv\", \"qry\".\n\nMerges product_buy, add_to_cart, remove_from_cart, page_visit, and search_query into one dataframe (allv).\n\nCreates user sessions\n\nDefines a session gap of SESSION_GAP_MIN minutes (you’ll need to set this constant somewhere, e.g., SESSION_GAP_MIN = 30).\n\nIf a user’s next event is more than SESSION_GAP_MIN minutes after the last one, it starts a new session.\n\nAdds session_id (per user) and step (step number within that session).\n\nReturns a unified, sessionized dataframe\n\nEach row is now:\nclient_id | timestamp | sku/url/query | event_type | session_id | step","metadata":{}},{"cell_type":"markdown","source":"**Given a URL, what’s the distribution of product categories people looked at within 10 minutes of visiting it?**","metadata":{}},{"cell_type":"markdown","source":"# Version - 2","metadata":{}},{"cell_type":"code","source":"# RL Recommender – End-to-End (No Propensity)\n# -------------------------------------------------------------\n# What this file includes\n#   1) Data prep: clean + sessionize events (robust to missing cols)\n#   2) Optional downsampling: top-N popular SKUs and top-N active users\n#   3) Popularity model (global & per-category)\n#   4) URL→Category model (fast-ish with NumPy + tqdm)\n#   5) Candidate pool builder\n#   6) RL dataset builder (offline transitions from sessions)\n#   7) Dueling Double DQN agent + training loop\n#   8) Simple evaluation: HR@K, NDCG@K\n#\n# Notes\n# - This version intentionally DOES NOT use propensity files.\n# - Assumes input `data` dict has keys: 'product_buy', 'add_to_cart',\n#   'remove_from_cart', 'page_visit', 'search_query', 'product_properties'.\n# - You can run pieces independently if your RAM is tight (page_visit is large).\n\nfrom __future__ import annotations\nimport os\nfrom typing import Dict, Any, List, Tuple, Optional\nfrom collections import defaultdict, Counter\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# -----------------------------\n# Data loading\n# -----------------------------\n\ndef load_parquets_and_targets(data_dir: str) -> Dict[str, Any]:\n    \"\"\"Load parquet event files and target propensity numpy arrays.\n    Expects files described earlier.\n    \"\"\"\n    if USE_SYNTHETIC:\n        return make_synth_data_for_pipeline()\n\n    def rp(fname):\n        p = os.path.join(data_dir, fname)\n        if not os.path.exists(p):\n            raise FileNotFoundError(p)\n        return pd.read_parquet(p)\n\n    data = {}\n    data['product_properties'] = rp('product_properties.parquet')\n    data['product_buy'] = rp('product_buy.parquet')\n    data['add_to_cart'] = rp('add_to_cart.parquet')\n    data['remove_from_cart'] = rp('remove_from_cart.parquet')\n    data['page_visit'] = rp('page_visit.parquet')\n    data['search_query'] = rp('search_query.parquet')\n\n    # load numpy targets if present\n    targ_dir = os.path.join(data_dir, 'target')\n    if os.path.isdir(targ_dir):\n        def ln(p):\n            f = os.path.join(p)\n            if os.path.exists(f):\n                return np.load(f, allow_pickle=True)\n            return None\n        data['propensity_sku'] = None\n        data['propensity_category'] = None\n        sku_p = os.path.join(targ_dir, 'popularity_propensity_sku.npy')\n        cat_p = os.path.join(targ_dir, 'popularity_propensity_category.npy')\n        if os.path.exists(sku_p):\n            data['propensity_sku'] = np.load(sku_p, allow_pickle=True) if os.path.getsize(sku_p)>0 else None\n        if os.path.exists(cat_p):\n            data['propensity_category'] = np.load(cat_p, allow_pickle=True) if os.path.getsize(cat_p)>0 else None\n    else:\n        data['propensity_sku'] = None\n        data['propensity_category'] = None\n\n    return data\n\n\n# -----------------------------\n# 1) CLEAN + SESSIONIZE\n# -----------------------------\n\ndef clean_and_sessionize(data: Dict[str, Any], session_gap_min: int = 30) -> pd.DataFrame:\n    \"\"\"\n    Build a single sessionized event table from mixed event DataFrames.\n    Keeps only essential columns and is robust to missing columns/arrays.\n\n    Returns columns:\n      ['client_id','timestamp','sku','url','query','event_type','session_id','step']\n    \"\"\"\n    event_map = {\n        'product_buy': 'buy',\n        'add_to_cart': 'a2c',\n        'remove_from_cart': 'rmc',\n        'page_visit': 'pv',\n        'search_query': 'qry'\n    }\n\n    frames = []\n    for key in ['product_buy','add_to_cart','remove_from_cart','page_visit','search_query']:\n        val = data.get(key)\n        if val is None or not isinstance(val, pd.DataFrame) or len(val) == 0:\n            continue\n        df = val.copy()\n\n        # Ensure timestamp & client_id exist\n        if 'timestamp' in df.columns:\n            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, errors='coerce')\n        else:\n            df['timestamp'] = pd.NaT\n        if 'client_id' not in df.columns:\n            df['client_id'] = pd.NA\n\n        # Normalize payload columns\n        df['sku'] = df['sku'] if 'sku' in df.columns else pd.NA\n        df['url'] = df['url'] if 'url' in df.columns else pd.NA\n        df['query'] = df['query'] if 'query' in df.columns else pd.NA\n\n        # Coerce client_id numeric\n        df['client_id'] = pd.to_numeric(df['client_id'], errors='coerce')\n\n        df['event_type'] = event_map.get(key, key)\n        df = df[['client_id','timestamp','sku','url','query','event_type']]\n        frames.append(df)\n\n    if not frames:\n        return pd.DataFrame(columns=['client_id','timestamp','sku','url','query','event_type','session_id','step'])\n\n    allv = pd.concat(frames, ignore_index=True)\n    allv.dropna(subset=['client_id','timestamp'], inplace=True)\n    allv['client_id'] = allv['client_id'].astype('int64')\n\n    allv.sort_values(['client_id','timestamp'], inplace=True)\n\n    gap = pd.Timedelta(minutes=session_gap_min)\n    is_break = allv.groupby('client_id')['timestamp'].diff().gt(gap)\n    is_break = is_break.fillna(True)\n    sess_num = is_break.groupby(allv['client_id']).cumsum().astype(int)\n    allv['session_id'] = allv['client_id'].astype(str) + '_' + sess_num.astype(str)\n    allv['step'] = allv.groupby('session_id').cumcount() + 1\n\n    return allv.reset_index(drop=True)\n\n# ----------------------------------\n# 2) OPTIONAL DOWNSAMPLING FUNCTIONS\n# ----------------------------------\n\ndef filter_top_products(data: dict, top_n: int = 30000) -> dict:\n    \"\"\"Keep only events for top-N popular SKUs (by counts in buy+a2c+remove).\"\"\"\n    sku_counts = pd.Series(dtype=int)\n\n    for key in ['product_buy', 'add_to_cart', 'remove_from_cart']:\n        df = data.get(key)\n        if isinstance(df, pd.DataFrame) and 'sku' in df.columns:\n            sku_counts = sku_counts.add(df['sku'].value_counts(), fill_value=0)\n\n    if sku_counts.empty:\n        return data.copy()\n\n    popular_skus = set(sku_counts.sort_values(ascending=False).head(top_n).index)\n\n    out = {}\n    for k, v in data.items():\n        if isinstance(v, pd.DataFrame) and 'sku' in v.columns:\n            out[k] = v[v['sku'].isin(popular_skus)]  # no .copy()\n        else:\n            out[k] = v\n    return out\n\n\ndef filter_top_users(data: dict, top_n_users: int = 50000) -> dict:\n    \"\"\"Keep only top-N active users across all events (by total interactions).\"\"\"\n    user_activity = pd.Series(dtype=int)\n\n    for key in ['product_buy', 'add_to_cart', 'remove_from_cart', 'page_visit', 'search_query']:\n        df = data.get(key)\n        if isinstance(df, pd.DataFrame) and 'client_id' in df.columns:\n            user_activity = user_activity.add(df['client_id'].value_counts(), fill_value=0)\n\n    if user_activity.empty:\n        return data.copy()\n\n    top_users = set(user_activity.sort_values(ascending=False).head(top_n_users).index)\n\n    out = {}\n    for k, v in data.items():\n        if isinstance(v, pd.DataFrame) and 'client_id' in v.columns:\n            out[k] = v[v['client_id'].isin(top_users)]  # no .copy()\n        else:\n            out[k] = v\n    return out\n\n\n\n# -----------------------------\n# 3) POPULARITY MODEL\n# -----------------------------\n\ndef build_popularity_model(sessionized: pd.DataFrame, product_properties: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n    \"\"\"Return df with sku, count, optional category/price from product_properties.\"\"\"\n    # Count interactions for items (buy + a2c prioritized; fall back to any sku event)\n    item_df = sessionized[sessionized['sku'].notna()].copy()\n    item_df['sku'] = item_df['sku'].astype('int64')\n    weights = {'buy': 3.0, 'a2c': 1.5, 'rmc': -1.0, 'pv': 0.2, 'qry': 0.0}\n    item_df['w'] = item_df['event_type'].map(weights).fillna(0.0)\n\n    pop = (\n        item_df.groupby('sku')['w']\n        .sum()\n        .reset_index()\n        .rename(columns={'w':'score'})\n        .sort_values('score', ascending=False)\n        .reset_index(drop=True)\n    )\n\n    if isinstance(product_properties, pd.DataFrame) and not product_properties.empty:\n        meta = product_properties[['sku','category','price']].drop_duplicates('sku')\n        pop = pop.merge(meta, on='sku', how='left')\n    return pop\n\n# ---------------------------------------------\n# 4) URL → CATEGORY MODEL (FAST W/ TQDM)\n# ---------------------------------------------\n\ndef build_url_category_model_fast(\n    pv: pd.DataFrame,\n    item_events: pd.DataFrame,\n    product_properties: pd.DataFrame,\n    window_min: int = 10\n) -> Dict[int, Dict[int, float]]:\n    \"\"\"\n    For each URL, estimate distribution over product categories by\n    looking at item events from the same client that occur within\n    [pv_time, pv_time + window]. Faster than nested iterrows.\n    \"\"\"\n    if pv is None or item_events is None or len(pv) == 0 or len(item_events) == 0:\n        return {}\n\n    # Map sku→category upfront\n    prod_cat = product_properties.set_index('sku')['category'].to_dict()\n\n    # Keep only necessary columns\n    pv = pv[['client_id','timestamp','url']].copy()\n    item_events = item_events[['client_id','timestamp','sku']].copy()\n\n    # Ensure dtypes\n    pv['timestamp'] = pd.to_datetime(pv['timestamp'], utc=True, errors='coerce')\n    item_events['timestamp'] = pd.to_datetime(item_events['timestamp'], utc=True, errors='coerce')\n\n    pv.dropna(subset=['client_id','timestamp','url'], inplace=True)\n    item_events.dropna(subset=['client_id','timestamp','sku'], inplace=True)\n\n    pv.sort_values(['client_id','timestamp'], inplace=True)\n    item_events.sort_values(['client_id','timestamp'], inplace=True)\n\n    window = pd.Timedelta(minutes=window_min)\n    counts: Dict[int, Counter] = defaultdict(Counter)\n\n    # Group once to avoid repeated boolean indexing\n    item_groups = {cid: g for cid, g in item_events.groupby('client_id')}\n\n    for cid, gpv in tqdm(pv.groupby('client_id'), desc='URL→Category: clients'):\n        gi = item_groups.get(cid)\n        if gi is None or gi.empty:\n            continue\n        gi_times = gi['timestamp'].to_numpy()\n        gi_skus = gi['sku'].to_numpy()\n\n        # two-pointer style scan per pageview timestamp using vectorized masking\n        for t, url in zip(gpv['timestamp'].to_numpy(), gpv['url'].to_numpy()):\n            # mask for [t, t+window]\n            mask = (gi_times >= t) & (gi_times <= t + window)\n            if not mask.any():\n                continue\n            for sku in gi_skus[mask]:\n                if pd.isna(sku):\n                    continue\n                sku_int = int(sku)\n                cat = prod_cat.get(sku_int)\n                if cat is not None:\n                    counts[int(url)][int(cat)] += 1\n\n    # Normalize to probabilities per URL\n    model: Dict[int, Dict[int, float]] = {}\n    for url, c in counts.items():\n        total = sum(c.values())\n        if total <= 0:\n            continue\n        model[url] = {cat: cnt/total for cat, cnt in c.items()}\n    return model\n\n# ----------------------------------\n# 5) CANDIDATE POOLS\n# ----------------------------------\n\ndef build_candidate_pool(popularity_df: pd.DataFrame, top_k: int = 5000) -> np.ndarray:\n    \"\"\"Return array of top-K SKU ids to restrict action space.\"\"\"\n    skus = popularity_df['sku'].head(top_k).astype('int64').to_numpy()\n    return skus\n\n# ----------------------------------\n# 6) RL DATASET (OFFLINE TRANSITIONS)\n# ----------------------------------\n\ndef make_offline_transitions(\n    sessionized: pd.DataFrame,\n    max_hist: int,\n    event_reward: Optional[Dict[str, float]] = None,\n    candidate_skus: Optional[np.ndarray] = None,\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Create (s, a, r, s_next, done) from sessionized logs.\n    - State: last `max_hist` item ids (zero-padded), integers\n    - Action: the *actual* next item sku (behavior policy)\n    - Reward: mapped from that next event type\n    - done: session end flag\n    \"\"\"\n    if event_reward is None:\n        event_reward = {'buy': 1.0, 'a2c': 0.5, 'rmc': -0.2, 'pv': 0.05, 'qry': 0.0}\n\n    seq = sessionized.copy()\n    seq = seq[seq['sku'].notna()].copy()\n    seq['sku'] = seq['sku'].astype('int64')\n\n    # Optionally restrict to candidates\n    if candidate_skus is not None:\n        cand_set = set(candidate_skus.tolist())\n        seq = seq[seq['sku'].isin(cand_set)]\n\n    states, actions, rewards, next_states, dones = [], [], [], [], []\n\n    for sid, g in tqdm(seq.groupby('session_id'), desc='Building offline transitions'):\n        # For this simple builder, we use only item events within the session\n        g = g[['client_id','timestamp','sku','event_type','step']].sort_values('timestamp')\n        hist: List[int] = []\n\n        for i in range(len(g)-1):\n            # build state from history up to i (exclusive)\n            cur_sku = int(g.iloc[i]['sku'])\n            hist.append(cur_sku)\n            if len(hist) > max_hist:\n                hist = hist[-max_hist:]\n            state = np.zeros(max_hist, dtype=np.int64)\n            state[-len(hist):] = np.array(hist, dtype=np.int64)\n\n            # next event defines action & reward\n            nxt = g.iloc[i+1]\n            action = int(nxt['sku'])\n            reward = float(event_reward.get(str(nxt['event_type']), 0.0))\n\n            # build next_state (history including next action)\n            hist_next = hist + [action]\n            if len(hist_next) > max_hist:\n                hist_next = hist_next[-max_hist:]\n            next_state = np.zeros(max_hist, dtype=np.int64)\n            next_state[-len(hist_next):] = np.array(hist_next, dtype=np.int64)\n\n            done = (i+1 == len(g)-1)\n\n            states.append(state)\n            actions.append(action)\n            rewards.append(reward)\n            next_states.append(next_state)\n            dones.append(done)\n\n    if not states:\n        return (np.zeros((0,max_hist),dtype=np.int64),\n                np.zeros((0,),dtype=np.int64),\n                np.zeros((0,),dtype=np.float32),\n                np.zeros((0,max_hist),dtype=np.int64),\n                np.zeros((0,),dtype=np.bool_))\n\n    return (\n        np.stack(states),\n        np.array(actions, dtype=np.int64),\n        np.array(rewards, dtype=np.float32),\n        np.stack(next_states),\n        np.array(dones, dtype=np.bool_)\n    )\n\n# ----------------------------------\n# 7) DQN (Dueling + Double)\n# ----------------------------------\n\nclass DuelingDQN(nn.Module):\n    def __init__(self, num_items: int, emb_dim: int = 64, hist_len: int = 20, hidden: int = 256):\n        super().__init__()\n        self.num_items = num_items\n        self.hist_len = hist_len\n        self.item_emb = nn.Embedding(num_items + 1, emb_dim, padding_idx=0)\n        self.backbone = nn.Sequential(\n            nn.Linear(hist_len * emb_dim, hidden), nn.ReLU(),\n            nn.Linear(hidden, hidden), nn.ReLU(),\n        )\n        # Dueling streams\n        self.V = nn.Sequential(nn.Linear(hidden, 128), nn.ReLU(), nn.Linear(128, 1))\n        self.A = nn.Sequential(nn.Linear(hidden, 128), nn.ReLU(), nn.Linear(128, num_items))\n\n    def forward(self, state_idx: torch.LongTensor) -> torch.Tensor:\n        # state_idx: [B, hist_len] integer item ids (0 is padding)\n        emb = self.item_emb(state_idx)               # [B, hist_len, emb]\n        flat = emb.view(emb.size(0), -1)             # [B, hist_len*emb]\n        h = self.backbone(flat)\n        V = self.V(h)                                # [B, 1]\n        A = self.A(h)                                # [B, num_items]\n        Q = V + A - A.mean(dim=1, keepdim=True)\n        return Q\n\n# Utilities for mapping SKU ids ↔ action indices\nclass ActionSpace:\n    def __init__(self, candidate_skus: np.ndarray):\n        self.skus = candidate_skus.astype('int64')\n        self.sku2idx = {int(s): i for i, s in enumerate(self.skus)}\n    def to_index(self, sku_array: np.ndarray) -> np.ndarray:\n        return np.array([self.sku2idx.get(int(s), -1) for s in sku_array], dtype=np.int64)\n\n# Training step\n@torch.no_grad()\ndef compute_td_target(target_net, next_states, rewards, dones, gamma):\n    # Double DQN: action selection by online net, evaluation by target net\n    # (handled in train loop)\n    pass  # kept here for clarity; implemented inline in train()\n\n\ndef train_dqn_old(\n    transitions: Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n    action_space: ActionSpace,\n    hist_len: int = 20,\n    emb_dim: int = 64,\n    hidden: int = 256,\n    gamma: float = 0.99,\n    lr: float = 1e-3,\n    batch_size: int = 1024,\n    epochs: int = 5,\n    target_sync: int = 1000,\n    device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n):\n    states, actions_sku, rewards, next_states, dones = transitions\n    # Map actions from SKU ids to action indices within candidate set\n    idx_actions = action_space.to_index(actions_sku)\n    valid_mask = idx_actions >= 0\n\n    states = torch.from_numpy(states[valid_mask]).to(device)\n    next_states = torch.from_numpy(next_states[valid_mask]).to(device)\n    actions = torch.from_numpy(idx_actions[valid_mask]).long().to(device)\n    rewards = torch.from_numpy(rewards[valid_mask]).float().to(device)\n    dones = torch.from_numpy(dones[valid_mask]).bool().to(device)\n\n    num_items = len(action_space.skus)\n\n    online = DuelingDQN(num_items, emb_dim, hist_len, hidden).to(device)\n    target = DuelingDQN(num_items, emb_dim, hist_len, hidden).to(device)\n    target.load_state_dict(online.state_dict())\n    target.eval()\n\n    opt = optim.Adam(online.parameters(), lr=lr)\n    mse = nn.MSELoss()\n\n    N = states.size(0)\n    idx = np.arange(N)\n    step = 0\n\n    for ep in range(epochs):\n        np.random.shuffle(idx)\n        for start in tqdm(range(0, N, batch_size), desc=f'Epoch {ep+1}/{epochs}'):\n            step += 1\n            batch = idx[start:start+batch_size]\n            s = states[batch]\n            a = actions[batch]\n            r = rewards[batch]\n            ns = next_states[batch]\n            d = dones[batch]\n\n            q = online(s)                           # [B, num_items]\n            q_a = q.gather(1, a.unsqueeze(1)).squeeze(1)\n\n            with torch.no_grad():\n                # Double DQN\n                next_q_online = online(ns)          # action selection\n                best_a = next_q_online.argmax(dim=1, keepdim=True)\n                next_q_target = target(ns)          # action evaluation\n                next_q = next_q_target.gather(1, best_a).squeeze(1)\n                y = r + (~d).float() * gamma * next_q\n\n            loss = mse(q_a, y)\n            opt.zero_grad()\n            loss.backward()\n            nn.utils.clip_grad_norm_(online.parameters(), 1.0)\n            opt.step()\n\n            if step % target_sync == 0:\n                target.load_state_dict(online.state_dict())\n\n    return online, target\n\n# ----------------------------------\n# 8) EVALUATION\n# ----------------------------------\n\ndef rank_topk(q_values: torch.Tensor, k: int) -> np.ndarray:\n    topk = torch.topk(q_values, k=k, dim=1).indices.detach().cpu().numpy()\n    return topk\n\n\ndef eval_hr_ndcg(\n    model: nn.Module,\n    transitions: Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n    action_space: ActionSpace,\n    hist_len: int = 20,\n    k: int = 10,\n    device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n) -> Tuple[float, float]:\n    states, actions_sku, _, _, _ = transitions\n    idx_actions = action_space.to_index(actions_sku)\n    valid = idx_actions >= 0\n\n    states = torch.from_numpy(states[valid]).to(device)\n    true_a = torch.from_numpy(idx_actions[valid]).long().to(device)\n\n    with torch.no_grad():\n        q = model(states)\n        topk = torch.topk(q, k=k, dim=1).indices\n        hit = (topk == true_a.unsqueeze(1)).any(dim=1).float().mean().item()\n\n        # NDCG@K\n        gains = torch.where(topk == true_a.unsqueeze(1), 1.0, 0.0)\n        # positions 1..K → log2(1+pos)\n        denom = torch.log2(torch.arange(2, k+2, device=gains.device).float())\n        dcg = (gains / denom).sum(dim=1)\n        idcg = torch.tensor([1.0/denom[0].item()], device=gains.device).repeat(len(dcg))\n        ndcg = (dcg / idcg).mean().item()\n\n    return hit, ndcg\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:31:47.322568Z","iopub.execute_input":"2025-08-19T17:31:47.322864Z","iopub.status.idle":"2025-08-19T17:31:56.191798Z","shell.execute_reply.started":"2025-08-19T17:31:47.322839Z","shell.execute_reply":"2025-08-19T17:31:56.191234Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# -----------------------------\n# Config\n# -----------------------------\nUSE_SYNTHETIC = False\nDATA_DIR = \"/kaggle/working/ubc_data_extracted\"  # <- set this to your extracted folder path\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\n\n# Embedding dims\nEMB_DIM_ITEM = 128\nEMB_DIM_QUERY = 128\nEMB_DIM_URL = 64\n\n# Sessionization\nSESSION_GAP_MIN = 30\nMAX_STEPS_PER_SESSION = 20\n\n# Candidate gen\nCANDIDATE_POOL_SIZE = 200\n\n# Reward weights (dense reward)\nW_BUY = 5.0\nW_A2C = 2.0\nW_RMC = 1.0\nW_CAT = 0.5\nW_PV = 0.2\nW_QRY = 0.2\nW_DIV = 0.1\nW_REP = 0.2\nTIME_DECAY_TAU_SEC = 60.0\nGAMMA = 0.9\n\n# Training\nBATCH_SIZE = 128\nREPLAY_CAP = 200_000\nLR = 1e-3\nEPSILON_START = 0.2\nEPSILON_END = 0.05\nEPSILON_DECAY_STEPS = 50_000\nTARGET_UPDATE_FREQ = 2_000\nTRAIN_STEPS = 50_000\nEVAL_EVERY = 5_000\nTOPK = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:31:56.193069Z","iopub.execute_input":"2025-08-19T17:31:56.193706Z","iopub.status.idle":"2025-08-19T17:31:56.205871Z","shell.execute_reply.started":"2025-08-19T17:31:56.193687Z","shell.execute_reply":"2025-08-19T17:31:56.205352Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/working/ubc_data_extracted\"\n\nimport time\n\nst = time.time()\nprint('Loading data...')\ndata = load_parquets_and_targets(DATA_DIR)\nen = time.time()\nprint((en-st)/60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:31:56.206521Z","iopub.execute_input":"2025-08-19T17:31:56.206780Z","iopub.status.idle":"2025-08-19T17:32:06.929618Z","shell.execute_reply.started":"2025-08-19T17:31:56.206763Z","shell.execute_reply":"2025-08-19T17:32:06.929010Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n0.17840198278427125\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"for key, value in data.items():\n    if isinstance(value, pd.DataFrame):\n        print(f\"{key}: shape={value.shape}\")\n    elif isinstance(value, np.ndarray):\n        print(f\"{key}: ndarray shape={value.shape}\")\n    else:\n        print(f\"{key}: type={type(value)}, value={value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:32:06.930810Z","iopub.execute_input":"2025-08-19T17:32:06.931058Z","iopub.status.idle":"2025-08-19T17:32:06.935471Z","shell.execute_reply.started":"2025-08-19T17:32:06.931039Z","shell.execute_reply":"2025-08-19T17:32:06.934788Z"}},"outputs":[{"name":"stdout","text":"product_properties: shape=(1260365, 4)\nproduct_buy: shape=(1775394, 3)\nadd_to_cart: shape=(5674064, 3)\nremove_from_cart: shape=(1937170, 3)\npage_visit: shape=(156032014, 3)\nsearch_query: shape=(10218831, 3)\npropensity_sku: ndarray shape=(100,)\npropensity_category: ndarray shape=(100,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"st = time.time()\ndata_small = filter_top_products(data, top_n=5000)\ndata_small = filter_top_users(data_small, top_n_users=100000)\nen = time.time()\nprint((en-st)/60)\nprint(\"DONE !!!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:32:11.743973Z","iopub.execute_input":"2025-08-19T17:32:11.744241Z","iopub.status.idle":"2025-08-19T17:32:45.918261Z","shell.execute_reply.started":"2025-08-19T17:32:11.744223Z","shell.execute_reply":"2025-08-19T17:32:45.917521Z"}},"outputs":[{"name":"stdout","text":"0.569500990708669\nDONE !!!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"for key, value in data_small.items():\n    if isinstance(value, pd.DataFrame):\n        print(f\"{key}: shape={value.shape}\")\n    elif isinstance(value, np.ndarray):\n        print(f\"{key}: ndarray shape={value.shape}\")\n    else:\n        print(f\"{key}: type={type(value)}, value={value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:32:45.919383Z","iopub.execute_input":"2025-08-19T17:32:45.919649Z","iopub.status.idle":"2025-08-19T17:32:45.924621Z","shell.execute_reply.started":"2025-08-19T17:32:45.919632Z","shell.execute_reply":"2025-08-19T17:32:45.923983Z"}},"outputs":[{"name":"stdout","text":"product_properties: shape=(5000, 4)\nproduct_buy: shape=(94748, 3)\nadd_to_cart: shape=(375782, 3)\nremove_from_cart: shape=(173640, 3)\npage_visit: shape=(33535779, 3)\nsearch_query: shape=(4039900, 3)\npropensity_sku: ndarray shape=(100,)\npropensity_category: ndarray shape=(100,)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 2) Sessionize\nimport time\n\nst = time.time()\nallv = clean_and_sessionize(data_small, session_gap_min=60)\nen = time.time()\nprint((en-st)/60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:32:55.507315Z","iopub.execute_input":"2025-08-19T17:32:55.507568Z","iopub.status.idle":"2025-08-19T17:34:53.390215Z","shell.execute_reply.started":"2025-08-19T17:32:55.507549Z","shell.execute_reply":"2025-08-19T17:34:53.389554Z"}},"outputs":[{"name":"stdout","text":"1.9646497964859009\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 3) Popularity + candidates\n\nst = time.time()\npop = build_popularity_model(allv, data_small.get('product_properties'))\ncandidates = build_candidate_pool(pop, top_k=50000)\nen = time.time()\nprint((en-st)/60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:34:57.365486Z","iopub.execute_input":"2025-08-19T17:34:57.365741Z","iopub.status.idle":"2025-08-19T17:34:58.269413Z","shell.execute_reply.started":"2025-08-19T17:34:57.365724Z","shell.execute_reply":"2025-08-19T17:34:58.268790Z"}},"outputs":[{"name":"stdout","text":"0.01499934991200765\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 4) URL→Category model (optional, for features or heuristics)\n\nitem_events = pd.concat([\n     data_small.get('product_buy', pd.DataFrame()),\n     data_small.get('add_to_cart', pd.DataFrame())\n ], ignore_index=True)\nurl_cat = build_url_category_model_fast(data_small.get('page_visit', pd.DataFrame()), item_events, data_small['product_properties'], window_min=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:35:06.930236Z","iopub.execute_input":"2025-08-19T17:35:06.930460Z","iopub.status.idle":"2025-08-19T17:41:27.277764Z","shell.execute_reply.started":"2025-08-19T17:35:06.930445Z","shell.execute_reply":"2025-08-19T17:41:27.277203Z"}},"outputs":[{"name":"stderr","text":"URL→Category: clients: 100%|██████████| 99997/99997 [06:05<00:00, 273.71it/s]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 5) Offline transitions for RL\n#st = time.time()\ntrans = make_offline_transitions(allv, max_hist=20, candidate_skus=candidates)\n#en = time.time()\n\n#print((en-st)/60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:41:27.279023Z","iopub.execute_input":"2025-08-19T17:41:27.279276Z","iopub.status.idle":"2025-08-19T17:44:47.194594Z","shell.execute_reply.started":"2025-08-19T17:41:27.279255Z","shell.execute_reply":"2025-08-19T17:44:47.193996Z"}},"outputs":[{"name":"stderr","text":"Building offline transitions: 100%|██████████| 207753/207753 [03:11<00:00, 1086.41it/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Create action space mapping\naction_space = ActionSpace(candidates)\nprint(f\"Action space size: {len(action_space.skus)}\")\n\n# Get transitions\nstates, actions_sku, rewards, next_states, dones = trans\n\n# Map actions to candidate space indices\nactions_mapped = action_space.to_index(actions_sku)\nvalid_mask = actions_mapped >= 0  # Keep only valid actions\n\n# Apply valid mask to all arrays\nstates_valid = states[valid_mask]\nactions_valid = actions_mapped[valid_mask]\nrewards_valid = rewards[valid_mask]\nnext_states_valid = next_states[valid_mask]\ndones_valid = dones[valid_mask]\n\nprint(f\"Valid transitions: {len(states_valid)}\")\n\n# Map states and next_states to candidate space\ndef map_state_to_candidates(state_array):\n    \"\"\"Map state array (containing SKU IDs) to candidate indices\"\"\"\n    mapped = np.zeros_like(state_array, dtype=np.int64)\n    for i in range(state_array.shape[0]):  # for each sequence\n        for j in range(state_array.shape[1]):  # for each position in sequence\n            sku = state_array[i, j]\n            if sku == 0:  # padding\n                mapped[i, j] = 0\n            else:\n                idx = action_space.sku2idx.get(int(sku), -1)\n                if idx >= 0:\n                    mapped[i, j] = idx + 1  # +1 to reserve 0 for padding\n                else:\n                    mapped[i, j] = 0  # unknown SKU -> padding\n    return mapped\n\nprint(\"Mapping states...\")\nstates_mapped = map_state_to_candidates(states_valid)\n\nprint(\"Mapping next_states...\")\nnext_states_mapped = map_state_to_candidates(next_states_valid)\n\n# Adjust actions to account for +1 offset (since 0 is padding in embedding)\nactions_final = actions_valid + 1\n\nprint(f\"Final ranges:\")\nprint(f\"States: {states_mapped.min()}-{states_mapped.max()}\")\nprint(f\"Actions: {actions_final.min()}-{actions_final.max()}\")\nprint(f\"Next states: {next_states_mapped.min()}-{next_states_mapped.max()}\")\n\n# Embedding size should be num_candidates + 1 (for padding)\nnum_items_embedding = len(action_space.skus) + 1\nnum_items_actions = len(action_space.skus)\n\nprint(f\"Embedding size: {num_items_embedding}\")\nprint(f\"Action space size: {num_items_actions}\")\n\n# Create transitions tuple\ntrans_final = (states_mapped, actions_final, rewards_valid, next_states_mapped, dones_valid)\n\n# Modified DQN class to handle the size mismatch\nclass DQN_Fixed(nn.Module):\n    def __init__(self, num_items_embedding, num_items_actions, emb_dim=64, hidden=256):\n        super().__init__()\n        self.embedding = nn.Embedding(num_items_embedding, emb_dim, padding_idx=0)\n        self.fc1 = nn.Linear(emb_dim, hidden)\n        self.fc2 = nn.Linear(hidden, hidden)\n        self.fc_out = nn.Linear(hidden, num_items_actions)  # Output only valid actions\n\n    def forward(self, x):\n        # x: [batch, hist_len]\n        x = self.embedding(x)                 # [batch, hist_len, emb_dim]\n        x = x.mean(dim=1)                     # aggregate history\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        return self.fc_out(x)                 # [batch, num_items_actions]\n\n# Training function with fixed sizes and tqdm progress bars\ndef train_dqn_tqdm(transitions, num_items_embedding, num_items_actions, hist_len=20, emb_dim=64, hidden=256,\n                    gamma=0.99, lr=1e-3, batch_size=64, epochs=3, device=\"cpu\"):\n    \n    states, actions, rewards, next_states, dones = transitions\n    \n    # Actions should be in range [1, num_items_actions] (since we added +1)\n    # We need to convert them back to [0, num_items_actions-1] for gather operation\n    actions = actions - 1  # Convert back to 0-indexed for gather\n    \n    # Initialize networks\n    online = DQN_Fixed(num_items_embedding, num_items_actions, emb_dim, hidden).to(device)\n    target = DQN_Fixed(num_items_embedding, num_items_actions, emb_dim, hidden).to(device)\n    target.load_state_dict(online.state_dict())\n    \n    optimizer = optim.Adam(online.parameters(), lr=lr)\n    loss_fn = nn.MSELoss()\n    \n    N = len(states)\n    num_batches = (N + batch_size - 1) // batch_size  # Calculate total batches per epoch\n    \n    # Outer progress bar for epochs\n    epoch_pbar = tqdm(range(epochs), desc=\"Training DQN\", unit=\"epoch\")\n    \n    for epoch in epoch_pbar:\n        idx = np.random.permutation(N)\n        total_loss = 0.0\n        \n        # Inner progress bar for batches within each epoch\n        batch_pbar = tqdm(range(0, N, batch_size), \n                         desc=f\"Epoch {epoch+1}/{epochs}\", \n                         unit=\"batch\",\n                         leave=False)  # Don't leave the inner progress bar after completion\n        \n        for i in batch_pbar:\n            batch_idx = idx[i:i+batch_size]\n            \n            b_states = torch.tensor(states[batch_idx], dtype=torch.long, device=device)\n            b_actions = torch.tensor(actions[batch_idx], dtype=torch.long, device=device)\n            b_rewards = torch.tensor(rewards[batch_idx], dtype=torch.float, device=device)\n            b_next_states = torch.tensor(next_states[batch_idx], dtype=torch.long, device=device)\n            b_dones = torch.tensor(dones[batch_idx], dtype=torch.float, device=device)\n            \n            # Q(s,a)\n            q_values = online(b_states).gather(1, b_actions.unsqueeze(1)).squeeze(1)\n            \n            # target Q\n            with torch.no_grad():\n                max_next_q = target(b_next_states).max(1)[0]\n                target_q = b_rewards + gamma * max_next_q * (1 - b_dones)\n            \n            # Loss + update\n            loss = loss_fn(q_values, target_q)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            batch_loss = loss.item()\n            total_loss += batch_loss\n            \n            # Update batch progress bar with current loss\n            batch_pbar.set_postfix({\n                'batch_loss': f'{batch_loss:.4f}',\n                'avg_loss': f'{total_loss / ((i // batch_size) + 1):.4f}'\n            })\n        \n        # Close batch progress bar\n        batch_pbar.close()\n        \n        # Update epoch progress bar with epoch summary\n        avg_epoch_loss = total_loss / num_batches\n        epoch_pbar.set_postfix({\n            'epoch_loss': f'{avg_epoch_loss:.4f}',\n            'total_loss': f'{total_loss:.4f}'\n        })\n        \n        # Update target network\n        target.load_state_dict(online.state_dict())\n    \n    # Close epoch progress bar\n    epoch_pbar.close()\n    \n    return online, target\n\n# Training function with fixed sizes\ndef train_dqn_fixed(transitions, num_items_embedding, num_items_actions, hist_len=20, emb_dim=64, hidden=256,\n                    gamma=0.99, lr=1e-3, batch_size=64, epochs=3, device=\"cpu\"):\n\n    states, actions, rewards, next_states, dones = transitions\n\n    # Actions should be in range [1, num_items_actions] (since we added +1)\n    # We need to convert them back to [0, num_items_actions-1] for gather operation\n    actions = actions - 1  # Convert back to 0-indexed for gather\n\n    # Initialize networks\n    online = DQN_Fixed(num_items_embedding, num_items_actions, emb_dim, hidden).to(device)\n    target = DQN_Fixed(num_items_embedding, num_items_actions, emb_dim, hidden).to(device)\n    target.load_state_dict(online.state_dict())\n\n    optimizer = optim.Adam(online.parameters(), lr=lr)\n    loss_fn = nn.MSELoss()\n\n    N = len(states)\n\n    for epoch in range(epochs):\n        idx = np.random.permutation(N)\n        total_loss = 0.0\n\n        for i in range(0, N, batch_size):\n            batch_idx = idx[i:i+batch_size]\n\n            b_states = torch.tensor(states[batch_idx], dtype=torch.long, device=device)\n            b_actions = torch.tensor(actions[batch_idx], dtype=torch.long, device=device)\n            b_rewards = torch.tensor(rewards[batch_idx], dtype=torch.float, device=device)\n            b_next_states = torch.tensor(next_states[batch_idx], dtype=torch.long, device=device)\n            b_dones = torch.tensor(dones[batch_idx], dtype=torch.float, device=device)\n\n            # Q(s,a)\n            q_values = online(b_states).gather(1, b_actions.unsqueeze(1)).squeeze(1)\n\n            # target Q\n            with torch.no_grad():\n                max_next_q = target(b_next_states).max(1)[0]\n                target_q = b_rewards + gamma * max_next_q * (1 - b_dones)\n\n            # Loss + update\n            loss = loss_fn(q_values, target_q)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}/{epochs}, Loss={total_loss:.4f}\")\n\n        # Update target network\n        target.load_state_dict(online.state_dict())\n\n    return online, target\n\nfrom tqdm import tqdm\n\ndef train_dqn_fixed_tqdm(transitions, num_items_embedding, num_items_actions, hist_len=20, emb_dim=64, hidden=256,\n                    gamma=0.99, lr=1e-3, batch_size=64, epochs=3, device=\"cpu\"):\n\n    states, actions, rewards, next_states, dones = transitions\n    actions = actions - 1  # Convert back to 0-indexed for gather\n\n    online = DQN_Fixed(num_items_embedding, num_items_actions, emb_dim, hidden).to(device)\n    target = DQN_Fixed(num_items_embedding, num_items_actions, emb_dim, hidden).to(device)\n    target.load_state_dict(online.state_dict())\n\n    optimizer = optim.Adam(online.parameters(), lr=lr)\n    loss_fn = nn.MSELoss()\n\n    N = len(states)\n\n    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n        idx = np.random.permutation(N)\n        total_loss = 0.0\n\n        for i in range(0, N, batch_size):\n            batch_idx = idx[i:i+batch_size]\n\n            b_states = torch.tensor(states[batch_idx], dtype=torch.long, device=device)\n            b_actions = torch.tensor(actions[batch_idx], dtype=torch.long, device=device)\n            b_rewards = torch.tensor(rewards[batch_idx], dtype=torch.float, device=device)\n            b_next_states = torch.tensor(next_states[batch_idx], dtype=torch.long, device=device)\n            b_dones = torch.tensor(dones[batch_idx], dtype=torch.float, device=device)\n\n            q_values = online(b_states).gather(1, b_actions.unsqueeze(1)).squeeze(1)\n\n            with torch.no_grad():\n                max_next_q = target(b_next_states).max(1)[0]\n                target_q = b_rewards + gamma * max_next_q * (1 - b_dones)\n\n            loss = loss_fn(q_values, target_q)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        tqdm.write(f\"Epoch {epoch+1}/{epochs}, Loss={total_loss:.4f}\")\n        target.load_state_dict(online.state_dict())\n\n    return online, target\n\n\n# Train the model\nonline, target = train_dqn_fixed_tqdm(\n    trans_final, \n    num_items_embedding=num_items_embedding, \n    num_items_actions=num_items_actions,\n    hist_len=20, \n    emb_dim=128, \n    hidden=2048, \n    epochs=3, \n    batch_size=64,\n    device='cuda'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:44:47.195567Z","iopub.execute_input":"2025-08-19T17:44:47.195784Z","iopub.status.idle":"2025-08-19T17:47:24.059632Z","shell.execute_reply.started":"2025-08-19T17:44:47.195768Z","shell.execute_reply":"2025-08-19T17:47:24.058995Z"}},"outputs":[{"name":"stdout","text":"Action space size: 4996\nValid transitions: 436417\nMapping states...\nMapping next_states...\nFinal ranges:\nStates: 0-4996\nActions: 1-4996\nNext states: 0-4996\nEmbedding size: 4997\nAction space size: 4996\n","output_type":"stream"},{"name":"stderr","text":"Training Epochs:  33%|███▎      | 1/3 [00:49<01:38, 49.07s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3, Loss=1355.9142\n","output_type":"stream"},{"name":"stderr","text":"Training Epochs:  67%|██████▋   | 2/3 [01:36<00:48, 48.38s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3, Loss=2205.7069\n","output_type":"stream"},{"name":"stderr","text":"Training Epochs: 100%|██████████| 3/3 [02:25<00:00, 48.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 3/3, Loss=4657.2160\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Evaluation after training your model\nprint(\"Evaluating trained DQN model...\")\n\n# You need to create a modified ActionSpace class that works with your mapped data\nclass ActionSpaceEval:\n    def __init__(self, candidate_skus: np.ndarray):\n        self.skus = candidate_skus.astype('int64')\n        self.sku2idx = {int(s): i for i, s in enumerate(self.skus)}\n    \n    def to_index(self, sku_array: np.ndarray) -> np.ndarray:\n        # For evaluation, we need to handle the fact that our actions are already mapped\n        # This assumes sku_array contains the original SKU IDs\n        return np.array([self.sku2idx.get(int(s), -1) for s in sku_array], dtype=np.int64)\n\n# Create action space for evaluation (using original candidate SKUs)\naction_space_eval = ActionSpaceEval(candidates)\n\n# Prepare evaluation data - use the same mapped transitions we used for training\n# But we need to convert actions back to 0-indexed for evaluation\neval_transitions = (\n    states_mapped,           # Mapped states (with padding)\n    actions_final - 1,       # Convert back to 0-indexed actions for evaluation\n    rewards_valid,           # Rewards\n    next_states_mapped,      # Mapped next states\n    dones_valid             # Done flags\n)\n\n# Evaluate at different K values\nk_values = [20, 40, 60]\n\n# Check what device your model is on and match it\nmodel_device = next(online.parameters()).device\ndevice = str(model_device)\nprint(f\"Model is on device: {device}\")\n\n# Move model to CPU if needed (or keep on GPU)\nif device.startswith('cuda') and not torch.cuda.is_available():\n    print(\"CUDA not available, moving model to CPU...\")\n    online = online.cpu()\n    device = 'cpu'\nelif device == 'cpu' and torch.cuda.is_available():\n    print(\"CUDA available, you can move model to GPU for faster evaluation...\")\n    # Uncomment next line if you want to use GPU\n    # online = online.cuda()\n    # device = 'cuda'\n\nprint(f\"Evaluating on {len(eval_transitions[0])} test samples...\")\nprint(\"-\" * 50)\n\nfor k in k_values:\n    hr, ndcg = eval_hr_ndcg(\n        model=online,                    # Your trained model\n        transitions=eval_transitions,    # Evaluation data\n        action_space=action_space_eval,  # Action space mapping\n        hist_len=20,                    # Same as training\n        k=k,                            # Top-K for evaluation\n        device=device\n    )\n    \n    print(f\"HR@{k:2d}:   {hr:.4f}\")\n    print(f\"NDCG@{k:2d}: {ndcg:.4f}\")\n    print()\n\n# Optional: More detailed analysis\nprint(\"Model Architecture Summary:\")\nprint(f\"- Embedding size: {num_items_embedding}\")\nprint(f\"- Action space size: {num_items_actions}\")\nprint(f\"- Total parameters: {sum(p.numel() for p in online.parameters()):,}\")\nprint(f\"- Device: {next(online.parameters()).device}\")\n\n# Optional: Check some predictions\nprint(\"\\nSample Predictions:\")\nprint(\"-\" * 30)\n\n# Take first few samples for inspection\nsample_states = torch.tensor(states_mapped[:5], dtype=torch.long, device=device)\nwith torch.no_grad():\n    sample_q = online(sample_states)\n    top5_actions = torch.topk(sample_q, k=5, dim=1).indices\n    \n    for i in range(5):\n        print(f\"Sample {i+1}:\")\n        print(f\"  Input state (last 5 items): {states_mapped[i][-5:]}\")\n        print(f\"  True next action: {actions_final[i] - 1}\")  # Convert back to 0-indexed\n        print(f\"  Top 5 predicted actions: {top5_actions[i].cpu().numpy()}\")\n        print()\n\n# Optional: Action distribution analysis\nprint(\"Action Prediction Analysis:\")\nprint(\"-\" * 30)\nwith torch.no_grad():\n    # Make sure tensors are on the same device as model\n    analysis_states = torch.tensor(states_mapped[:1000], dtype=torch.long, device=device)\n    all_q = online(analysis_states)\n    top_actions = torch.topk(all_q, k=10, dim=1).indices\n    \n    # Count frequency of top predicted actions\n    from collections import Counter\n    action_counts = Counter(top_actions.flatten().cpu().numpy())\n    \n    print(\"Most frequently predicted actions (top 10):\")\n    for action_idx, count in action_counts.most_common(10):\n        # Convert back to original SKU ID\n        original_sku = candidates[action_idx] if action_idx < len(candidates) else \"Unknown\"\n        print(f\"  Action {action_idx} (SKU {original_sku}): {count} times\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T17:47:45.384885Z","iopub.execute_input":"2025-08-19T17:47:45.385619Z","iopub.status.idle":"2025-08-19T17:47:46.246530Z","shell.execute_reply.started":"2025-08-19T17:47:45.385596Z","shell.execute_reply":"2025-08-19T17:47:46.245709Z"}},"outputs":[{"name":"stdout","text":"Evaluating trained DQN model...\nModel is on device: cuda:0\nEvaluating on 436417 test samples...\n--------------------------------------------------\nHR@20:   0.0000\nNDCG@20: 0.0000\n\nHR@40:   0.0000\nNDCG@40: 0.0000\n\nHR@60:   0.0000\nNDCG@60: 0.0000\n\nModel Architecture Summary:\n- Embedding size: 4997\n- Action space size: 4996\n- Total parameters: 15,336,964\n- Device: cuda:0\n\nSample Predictions:\n------------------------------\nSample 1:\n  Input state (last 5 items): [   0    0    0    0 2892]\n  True next action: 2891\n  Top 5 predicted actions: [ 181  100  228 1232 2309]\n\nSample 2:\n  Input state (last 5 items): [   0    0    0 2892 2892]\n  True next action: 2891\n  Top 5 predicted actions: [ 100  333 4888 3965  181]\n\nSample 3:\n  Input state (last 5 items): [   0    0 2892 2892 2892]\n  True next action: 2891\n  Top 5 predicted actions: [4888 3965  333  100 1662]\n\nSample 4:\n  Input state (last 5 items): [   0 2892 2892 2892 2892]\n  True next action: 2891\n  Top 5 predicted actions: [4888 3965  100 1662  333]\n\nSample 5:\n  Input state (last 5 items): [2892 2892 2892 2892 2892]\n  True next action: 2891\n  Top 5 predicted actions: [4888 3965  214  100 2127]\n\nAction Prediction Analysis:\n------------------------------\nMost frequently predicted actions (top 10):\n  Action 3965 (SKU 1356019): 951 times\n  Action 100 (SKU 469819): 795 times\n  Action 4888 (SKU 1100135): 697 times\n  Action 333 (SKU 1541312): 633 times\n  Action 181 (SKU 91500): 626 times\n  Action 2309 (SKU 229720): 602 times\n  Action 268 (SKU 650506): 515 times\n  Action 1662 (SKU 821154): 336 times\n  Action 2134 (SKU 18167): 268 times\n  Action 1934 (SKU 1508324): 238 times\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# 7) Evaluate\n# hr, ndcg = eval_hr_ndcg(online, trans, action_space, hist_len=20, k=10)\n# print(f\"HR@10={hr:.4f}, NDCG@10={ndcg:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Diagnostic trio: GPU status, CPU forward sanity, guarded model->CUDA test\n# Run this as one cell in your notebook.\n\nimport os, traceback, sys\nimport numpy as np\nimport torch\n\n# Optional: If you want deterministic CUDA tracebacks, restart kernel and UNCOMMENT the next two lines\n# BEFORE importing torch in a fresh kernel:\n# import os\n# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\nprint(\"===== ENV & TORCH INFO =====\")\nprint(\"python:\", sys.version.splitlines()[0])\nprint(\"torch.__version__:\", getattr(torch, \"__version__\", None))\nprint(\"cuda available:\", torch.cuda.is_available())\nprint(\"cuda device count:\", torch.cuda.device_count())\nif torch.cuda.is_available():\n    try:\n        dev = torch.cuda.current_device()\n        print(\"current device:\", dev)\n        try:\n            print(\"device name:\", torch.cuda.get_device_name(dev))\n        except Exception as e:\n            print(\"device name query failed:\", e)\n        try:\n            print(\"allocated (bytes):\", torch.cuda.memory_allocated(dev))\n            print(\"reserved  (bytes):\", torch.cuda.memory_reserved(dev))\n        except Exception as e:\n            print(\"memory query failed:\", e)\n    except Exception as e:\n        print(\"cuda query failed:\", e)\nprint(\"=============================\\n\")\n\n# --- Parameters that must match your model shape ---\n# Make sure these match how you constructed the network earlier.\n# If you used different values, change them here before running.\nnum_items = len(action_space.skus) if 'action_space' in globals() else 500    # fallback guess\nhist_len = 20\nemb_dim = 64\nhidden = 256\n\nprint(\"Using (num_items, hist_len, emb_dim, hidden) =\", (num_items, hist_len, emb_dim, hidden))\nprint()\n\n# --- Create the model on CPU and run a tiny forward pass ---\nprint(\"1) Creating model on CPU and running a tiny forward pass...\")\ntry:\n    # Import your model class if defined in another module; otherwise rely on DuelingDQN in this notebook.\n    ModelClass = globals().get('DuelingDQN', None)\n    if ModelClass is None:\n        raise RuntimeError(\"DuelingDQN not found in globals() — define the class first or import it.\")\n\n    model = ModelClass(num_items, emb_dim, hist_len, hidden)   # CPU by default\n    print(\"Model instance created successfully on CPU.\")\n    # Build a small dummy input batch (values must be valid indices for the model embedding).\n    # If your embedding reserves pad index = num_items, allow values up to num_items.\n    pad_limit = num_items  # allowed max index for states: either num_items (if pad reserved) or num_items-1\n    dummy = np.zeros((4, hist_len), dtype=np.int64)            # small batch of zeros (padding)\n    # optionally set some example indices within valid range:\n    if pad_limit > 1:\n        dummy[0, -1] = min(pad_limit - 1, 1)\n        dummy[1, -2] = min(pad_limit - 1, 2)\n    dummy_t = torch.from_numpy(dummy).long()\n    out = model(dummy_t)\n    print(\"Forward OK, q shape:\", tuple(out.shape))\nexcept Exception:\n    print(\"Exception during CPU model creation / forward:\")\n    traceback.print_exc()\n    raise\n\nprint(\"\\n2) Attempting to move model to CUDA (if available) in guarded block...\")\ntry:\n    if torch.cuda.is_available():\n        try:\n            # sync & small free\n            torch.cuda.synchronize()\n        except Exception:\n            pass\n\n        try:\n            model_cuda = model.to('cuda')\n            # run a forward on GPU to ensure kernels launch\n            dummy_gpu = dummy_t.to('cuda')\n            out_gpu = model_cuda(dummy_gpu)\n            print(\"Model moved to CUDA and forward passed. q shape (CUDA):\", tuple(out_gpu.shape))\n        except Exception as ex:\n            print(\"Exception while moving model to CUDA or running forward on CUDA:\")\n            traceback.print_exc()\n            # Helpful hints printed to the user\n            print(\"\\n--- HINTS ---\")\n            print(\"1) If you haven't, try restarting the kernel and setting:\")\n            print(\"   import os; os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # THEN import torch\")\n            print(\"2) If the above doesn't help, try running on CPU: set device='cpu' in your training call.\")\n            print(\"3) If model->cuda fails only after earlier CUDA errors, a kernel restart usually clears the CUDA context.\")\n            print(\"4) You may also have mismatched driver/CUDA versions or an out-of-memory condition.\")\n    else:\n        print(\"CUDA not available; skipping model->CUDA test.\")\nexcept Exception:\n    print(\"Unexpected exception in CUDA test:\")\n    traceback.print_exc()\n\nprint(\"\\nAll diagnostics finished.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T18:14:31.497077Z","iopub.execute_input":"2025-08-16T18:14:31.497365Z","iopub.status.idle":"2025-08-16T18:14:31.678347Z","shell.execute_reply.started":"2025-08-16T18:14:31.497344Z","shell.execute_reply":"2025-08-16T18:14:31.677548Z"}},"outputs":[],"execution_count":null}]}